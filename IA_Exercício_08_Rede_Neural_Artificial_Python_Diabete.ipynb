{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5tVff4dgKyg"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8xB4G8ogKym"
      },
      "source": [
        "### Carregando Arquivo de Treinamento (.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5MRh5ZfgKyn",
        "outputId": "41f43471-859e-4308-aa70-d83014f19ead"
      },
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/samuelAnjos/redeNeuralPerceptronAnaliseDiabete/main/diabetes.csv'\n",
        "base_Treinamento = pd.read_csv(url,sep=',', encoding = 'latin1').values\n",
        "print(\"---------------------------------\")\n",
        "print(\"Dados dos Pacientes - TREINAMENTO\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Treinamento)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Treinamento[:, 0:9])\n",
        "\n",
        "print(\"----------------------------\")\n",
        "print(\"Classificação Supervisionada\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Treinamento[:, 8])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "Dados dos Pacientes - TREINAMENTO\n",
            "---------------------------------\n",
            "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
            "----------------------------\n",
            "Classificação Supervisionada\n",
            "----------------------------\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPpDXy7cgKyp"
      },
      "source": [
        "### Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4nvyQJegKyq",
        "outputId": "2cfbef82-2886-426d-e109-2e8e41e431c3"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "\n",
        "pregnancies = base_Treinamento[:,0]  \n",
        "glucose = base_Treinamento[:,1]\n",
        "bloodPressure = base_Treinamento[:,2]\n",
        "skinThickness = base_Treinamento[:,3]\n",
        "insulin = base_Treinamento[:,4]\n",
        "bmi = base_Treinamento[:,5]\n",
        "diabetesPedigreeFunction = base_Treinamento[:,6]\n",
        "age = base_Treinamento[:,7]\n",
        "\n",
        "classes = base_Treinamento[:,8]\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_norm = np.column_stack((pregnancies,glucose,bloodPressure,skinThickness,insulin,bmi,diabetesPedigreeFunction,age))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "print(\"Classificação Supervisionada - Numéricos\")\n",
        "print(\"----------------------------------------\")\n",
        "diagnostico_norm = np.hstack((classes))\n",
        "print(diagnostico_norm)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Atributos de Entrada - Numéricos\n",
            "--------------------------------\n",
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "----------------------------------------\n",
            "Classificação Supervisionada - Numéricos\n",
            "----------------------------------------\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4FUfD5gKyr"
      },
      "source": [
        "### Treinamento do Neurônio Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDmPLB5FgKys",
        "outputId": "33ad51ec-dfb8-4325-a7f8-f9587abce7c7"
      },
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "# Treinamento do Perceptron a partir dos atributos de entrada e classificações\n",
        "modelo = Perceptron()\n",
        "modelo.fit(atributos_norm, diagnostico_norm)\n",
        "\n",
        "# Acurácia do modelo, que é : 1 - (predições erradas / total de predições)\n",
        "# Acurácia do modelo: indica uma performance geral do modelo. \n",
        "# Dentre todas as classificações, quantas o modelo classificou corretamente;\n",
        "# (VP+VN)/N\n",
        "print('Acurácia: %.3f' % modelo.score(atributos_norm, diagnostico_norm))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMwrAoNwgKyt"
      },
      "source": [
        "### ----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKPw4jagKyu"
      },
      "source": [
        "# Validação do Aprendizado "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tUmMoPHgKyv"
      },
      "source": [
        "### Predição Simples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4MRpx9PgKyw",
        "outputId": "bdbb2227-cfbe-481c-ab34-6fa0737fe130"
      },
      "source": [
        "Andre = [[6,148,72,35,0,33.6,0.627,50]]\n",
        "print(\"Andre\", modelo.predict(Andre))\n",
        "Maria = [[8,183,64,0,0,23.3,0.672,32]]\n",
        "print(\"Maria\", modelo.predict(Maria))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Andre [1.]\n",
            "Maria [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VweXD-8_gKyx"
      },
      "source": [
        "### Predição a partir de base de dados (.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceg0-DfVgKyx",
        "outputId": "303909f6-3ebf-41cd-e860-0ef0dadaa09b"
      },
      "source": [
        "import pandas as pd\n",
        "# Carregando dados do arquivo CSV\n",
        "url = 'https://raw.githubusercontent.com/samuelAnjos/redeNeuralPerceptronAnaliseDiabete/main/testes.csv'\n",
        "base_Testes = pd.read_csv(url,sep=',', encoding = 'latin1').values\n",
        "print(\"----------------------------\")\n",
        "print(\"Dados dos Pacientes - TESTES\")\n",
        "print(\"----------------------------\")\n",
        "print(base_Testes)\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "# Extração dos Atributos a serem utilizadas pela rede\n",
        "print(\"Atributos de Entrada\")\n",
        "print(\"---------------------------------\")\n",
        "print(base_Testes[:, 0:9])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "Dados dos Pacientes - TESTES\n",
            "----------------------------\n",
            "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
            "  5.000e+01 1.000e+00]\n",
            " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
            "  3.100e+01 0.000e+00]\n",
            " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
            "  3.200e+01 1.000e+00]\n",
            " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01 0.000e+00]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01 1.000e+00]\n",
            " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
            "  3.000e+01 0.000e+00]\n",
            " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
            "  2.600e+01 1.000e+00]\n",
            " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
            "  2.900e+01 0.000e+00]\n",
            " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
            "  5.300e+01 1.000e+00]\n",
            " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
            "  5.400e+01 1.000e+00]\n",
            " [4.000e+00 1.100e+02 9.200e+01 0.000e+00 0.000e+00 3.760e+01 1.910e-01\n",
            "  3.000e+01 0.000e+00]\n",
            " [1.000e+01 1.680e+02 7.400e+01 0.000e+00 0.000e+00 3.800e+01 5.370e-01\n",
            "  3.400e+01 1.000e+00]\n",
            " [1.000e+01 1.390e+02 8.000e+01 0.000e+00 0.000e+00 2.710e+01 1.441e+00\n",
            "  5.700e+01 0.000e+00]\n",
            " [1.000e+00 1.890e+02 6.000e+01 2.300e+01 8.460e+02 3.010e+01 3.980e-01\n",
            "  5.900e+01 1.000e+00]\n",
            " [5.000e+00 1.660e+02 7.200e+01 1.900e+01 1.750e+02 2.580e+01 5.870e-01\n",
            "  5.100e+01 1.000e+00]\n",
            " [7.000e+00 1.000e+02 0.000e+00 0.000e+00 0.000e+00 3.000e+01 4.840e-01\n",
            "  3.200e+01 1.000e+00]\n",
            " [0.000e+00 1.180e+02 8.400e+01 4.700e+01 2.300e+02 4.580e+01 5.510e-01\n",
            "  3.100e+01 1.000e+00]\n",
            " [7.000e+00 1.070e+02 7.400e+01 0.000e+00 0.000e+00 2.960e+01 2.540e-01\n",
            "  3.100e+01 1.000e+00]\n",
            " [1.000e+00 1.030e+02 3.000e+01 3.800e+01 8.300e+01 4.330e+01 1.830e-01\n",
            "  3.300e+01 0.000e+00]]\n",
            "---------------------------------\n",
            "Atributos de Entrada\n",
            "---------------------------------\n",
            "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
            "  5.000e+01 1.000e+00]\n",
            " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
            "  3.100e+01 0.000e+00]\n",
            " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
            "  3.200e+01 1.000e+00]\n",
            " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
            "  2.100e+01 0.000e+00]\n",
            " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
            "  3.300e+01 1.000e+00]\n",
            " [5.000e+00 1.160e+02 7.400e+01 0.000e+00 0.000e+00 2.560e+01 2.010e-01\n",
            "  3.000e+01 0.000e+00]\n",
            " [3.000e+00 7.800e+01 5.000e+01 3.200e+01 8.800e+01 3.100e+01 2.480e-01\n",
            "  2.600e+01 1.000e+00]\n",
            " [1.000e+01 1.150e+02 0.000e+00 0.000e+00 0.000e+00 3.530e+01 1.340e-01\n",
            "  2.900e+01 0.000e+00]\n",
            " [2.000e+00 1.970e+02 7.000e+01 4.500e+01 5.430e+02 3.050e+01 1.580e-01\n",
            "  5.300e+01 1.000e+00]\n",
            " [8.000e+00 1.250e+02 9.600e+01 0.000e+00 0.000e+00 0.000e+00 2.320e-01\n",
            "  5.400e+01 1.000e+00]\n",
            " [4.000e+00 1.100e+02 9.200e+01 0.000e+00 0.000e+00 3.760e+01 1.910e-01\n",
            "  3.000e+01 0.000e+00]\n",
            " [1.000e+01 1.680e+02 7.400e+01 0.000e+00 0.000e+00 3.800e+01 5.370e-01\n",
            "  3.400e+01 1.000e+00]\n",
            " [1.000e+01 1.390e+02 8.000e+01 0.000e+00 0.000e+00 2.710e+01 1.441e+00\n",
            "  5.700e+01 0.000e+00]\n",
            " [1.000e+00 1.890e+02 6.000e+01 2.300e+01 8.460e+02 3.010e+01 3.980e-01\n",
            "  5.900e+01 1.000e+00]\n",
            " [5.000e+00 1.660e+02 7.200e+01 1.900e+01 1.750e+02 2.580e+01 5.870e-01\n",
            "  5.100e+01 1.000e+00]\n",
            " [7.000e+00 1.000e+02 0.000e+00 0.000e+00 0.000e+00 3.000e+01 4.840e-01\n",
            "  3.200e+01 1.000e+00]\n",
            " [0.000e+00 1.180e+02 8.400e+01 4.700e+01 2.300e+02 4.580e+01 5.510e-01\n",
            "  3.100e+01 1.000e+00]\n",
            " [7.000e+00 1.070e+02 7.400e+01 0.000e+00 0.000e+00 2.960e+01 2.540e-01\n",
            "  3.100e+01 1.000e+00]\n",
            " [1.000e+00 1.030e+02 3.000e+01 3.800e+01 8.300e+01 4.330e+01 1.830e-01\n",
            "  3.300e+01 0.000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6JQnLaEgKyx"
      },
      "source": [
        "### Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJM8C3IDgKyy",
        "outputId": "458ce104-1788-44d0-c74f-b1c9e41e2cd2"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Binarizador de rótulo\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "\n",
        "#A saída da transformação é também conhecido como codificação 1-de-n\n",
        "#Transforma valores categóricos equidistantes em valores binários equidistantes.\n",
        "#Atributos categóricos com valores sim e não\n",
        "pregnancies = base_Treinamento[:, 0]  \n",
        "glucose = base_Treinamento[:, 1]\n",
        "bloodPressure = base_Treinamento[:, 2]\n",
        "skinThickness = base_Treinamento[:, 3]\n",
        "insulin = base_Treinamento[:, 4]\n",
        "bmi = base_Treinamento[:, 5]\n",
        "diabetesPedigreeFunction = base_Treinamento[:, 6]\n",
        "age = base_Treinamento[:, 7]\n",
        "\n",
        "\n",
        "#Concatenação de Atributos (Colunas) \n",
        "atributos_norm = np.column_stack((pregnancies,glucose,bloodPressure,skinThickness,insulin,bmi,diabetesPedigreeFunction,age))\n",
        "print(\"--------------------------------\")\n",
        "print(\"Atributos de Entrada - Numéricos\")\n",
        "print(\"--------------------------------\")\n",
        "print(atributos_norm)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Atributos de Entrada - Numéricos\n",
            "--------------------------------\n",
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QO3B6S3gKyy"
      },
      "source": [
        "### Predição da Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZovGGdmgKyz",
        "outputId": "6ab97d5d-78b9-4140-a36d-d079c4576032"
      },
      "source": [
        "base_Predicao = modelo.predict((atributos_norm))\n",
        "print(\"Classificações: \", base_Predicao)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classificações:  [1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
            " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.\n",
            " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ZxJwGAgKyz"
      },
      "source": [
        "### Retorno aos valores Categóricos"
      ]
    }
  ]
}